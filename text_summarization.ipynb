{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roby290597/nlp_exercise/blob/main/bundestags_reden_analyse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import requests\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"extr\")\n",
        "\n",
        "from redner_extraction import extract_speeches, extract_all_speakers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AcL9PYxNY8zK"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['vertrieb', 'herstellung', 'sitzung-ort', 'herausgeber', 'issn', 'wahlperiode', 'sitzung-nr', 'sitzung-datum', 'sitzung-start-uhrzeit', 'sitzung-ende-uhrzeit', 'sitzung-naechste-datum', 'start-seitennr']\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.bundestag.de/resource/blob/1115000/21032.xml\" ### Bundestag Reden XML Datei vom November 2025\n",
        "response = requests.get(url)\n",
        "\n",
        "# XML in einen Tree parsen\n",
        "tree = ET.ElementTree(ET.fromstring(response.content))\n",
        "\n",
        "# Wurzel-Element abrufen\n",
        "root = tree.getroot()\n",
        "\n",
        "print(root.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOPPELT: Mandy Eißing\n",
            "DOPPELT: Peter Bohnhof\n",
            "DOPPELT: Mahmut Özdemir\n",
            "DOPPELT: Klaus Wiener\n",
            "DOPPELT: Mirze Edis\n"
          ]
        }
      ],
      "source": [
        "import sys  \n",
        "sys.path.append('C:/Users/brand/OneDrive/Desktop/AI_Selbststudium/ML_little/bundestag_reden/extr')  # Pfad zu deinem Modul\n",
        "\n",
        "from redner_extraction import extract_speeches\n",
        "\n",
        "reden = {}\n",
        "redner = []\n",
        "# Beispiel-Ausgabe\n",
        "for speech in extract_speeches(root):\n",
        "    #print(f\"Redner: {speech['name']}\\nRede: {speech['text'][:200]}...\\n\")\n",
        "    if speech['name'] not in redner:\n",
        "        redner.append(speech['name'])\n",
        "        reden[speech['name']] = speech['text']\n",
        "    else:\n",
        "        print(\"DOPPELT:\", speech['name'])\n",
        "        reden[speech['name']] += \"\\n Nächste Rede:\" + speech['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'vorname': 'Bärbel', 'nachname': 'Bas', 'fraktion': ''}\n",
            "{'vorname': 'Hans-Jürgen', 'nachname': 'Goßner', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Wilfried', 'nachname': 'Oellers', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Ricarda', 'nachname': 'Lang', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Pascal', 'nachname': 'Meiser', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Dagmar', 'nachname': 'Schmidt', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Peter', 'nachname': 'Bohnhof', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Sandra', 'nachname': 'Carstensen', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Armin', 'nachname': 'Grau', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Nora', 'nachname': 'Seitz', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Leif-Erik', 'nachname': 'Holm', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Peter', 'nachname': 'Aumer', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Jan', 'nachname': 'Dieren', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Elisabeth', 'nachname': 'Winkelmeier-Becker', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Tobias Matthias', 'nachname': 'Peterka', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Axel', 'nachname': 'Müller', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Lena', 'nachname': 'Gumnior', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Mahmut', 'nachname': 'Özdemir', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Luke', 'nachname': 'Hoß', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Christian', 'nachname': 'Moser', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Rainer', 'nachname': 'Galla', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Maja', 'nachname': 'Wallstein', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Helge', 'nachname': 'Limburg', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Johannes', 'nachname': 'Wiegelmann', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Knuth', 'nachname': 'Meyer-Soltau', 'fraktion': 'AfD'}\n",
            "{'vorname': 'David', 'nachname': 'Preisendanz', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Wolfram', 'nachname': 'Weimer', 'fraktion': ''}\n",
            "{'vorname': 'Götz', 'nachname': 'Frömming', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Elisabeth', 'nachname': 'Kaiser', 'fraktion': ''}\n",
            "{'vorname': 'Katrin', 'nachname': 'Göring-Eckardt', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Mandy', 'nachname': 'Eißing', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Ottilie', 'nachname': 'Klein', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Sven', 'nachname': 'Wendorf', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Franziska', 'nachname': 'Kersten', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Sepp', 'nachname': 'Müller', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Wolfgang', 'nachname': 'Dahler', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Birgit', 'nachname': 'Bessin', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Felix', 'nachname': 'Döring', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Misbah', 'nachname': 'Khan', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Konrad', 'nachname': 'Körner', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Anna', 'nachname': 'Rathert', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Reem', 'nachname': 'Alabali Radovan', 'fraktion': ''}\n",
            "{'vorname': 'Rocco', 'nachname': 'Kever', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Nicolas', 'nachname': 'Zippelius', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Claudia', 'nachname': 'Roth', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Mirze', 'nachname': 'Edis', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Klaus', 'nachname': 'Wiener', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Johann', 'nachname': 'Martel', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Thomas', 'nachname': 'Bareiß', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Matthias', 'nachname': 'Gastel', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Michael', 'nachname': 'Donth', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Ulrich', 'nachname': 'von Zons', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Anja', 'nachname': 'Troff-Schaffarzyk', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Luigi', 'nachname': 'Pantisano', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Henning', 'nachname': 'Rehbaum', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Maximilian', 'nachname': 'Kneller', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Jakob', 'nachname': 'Blankenburg', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Günter', 'nachname': 'Baumgartner', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Katherina', 'nachname': 'Reiche', 'fraktion': ''}\n",
            "{'vorname': 'Steffen', 'nachname': 'Kotré', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Daniel', 'nachname': 'Walter', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Katrin', 'nachname': 'Uhlig', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Jörg', 'nachname': 'Cezanne', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Tilman', 'nachname': 'Kuban', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Raimond', 'nachname': 'Scheirich', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Agnes', 'nachname': 'Conrad', 'fraktion': 'Die Linke'}\n",
            "{'vorname': 'Andreas', 'nachname': 'Lenz', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Andreas', 'nachname': 'Audretsch', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Dirk', 'nachname': 'Brandes', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Bernd', 'nachname': 'Rützel', 'fraktion': 'SPD'}\n",
            "{'vorname': 'Michael', 'nachname': 'Kellner', 'fraktion': 'BÜNDNIS\\xa090/DIE GRÜNEN'}\n",
            "{'vorname': 'Lars', 'nachname': 'Rohwer', 'fraktion': 'CDU/CSU'}\n",
            "{'vorname': 'Gerrit', 'nachname': 'Huy', 'fraktion': 'AfD'}\n",
            "{'vorname': 'Vanessa', 'nachname': 'Zobel', 'fraktion': 'CDU/CSU'}\n"
          ]
        }
      ],
      "source": [
        "from redner_extraction import extract_all_speakers\n",
        "\n",
        "redner_party = []\n",
        "all_speakers = extract_all_speakers(root)\n",
        "for speaker in all_speakers:\n",
        "    print(speaker)\n",
        "    redner_party.append((speaker['vorname'] + \" \" + speaker['nachname'], speaker['fraktion']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-8.69693458e-02  6.99105263e-02 -1.50974002e-02  9.65303257e-02\n",
            " -1.27644852e-01  1.39459781e-03  1.15716711e-01 -3.32799181e-03\n",
            "  3.84191871e-02 -1.18052520e-01  3.65473214e-04 -8.89995620e-02\n",
            "  1.83635729e-03 -2.63631474e-02  9.93321184e-03 -1.08354546e-01\n",
            "  1.04886509e-01 -1.18006552e-02 -4.96205017e-02 -3.73219512e-02\n",
            " -6.43265247e-02 -1.88605767e-02 -2.44027581e-02  2.12480426e-02\n",
            "  2.48730518e-02  8.56154636e-02  1.89984664e-02  5.53129287e-03\n",
            " -3.41179594e-02 -1.04084596e-01  2.01883037e-02  6.25705868e-02\n",
            "  9.53509957e-02 -1.24666980e-02 -1.74872633e-02  6.99081412e-03\n",
            "  3.52802724e-02 -5.11244945e-02  7.67797530e-02 -8.06917809e-03\n",
            "  3.78221311e-02 -4.43059392e-02  6.50362149e-02 -4.18957211e-02\n",
            " -5.06397011e-03  2.14370042e-02 -9.37890541e-03  5.28941527e-02\n",
            "  2.52480581e-02  3.13140340e-02 -7.02112988e-02  1.89095605e-02\n",
            " -6.05360270e-02  8.84522218e-03  2.80241035e-02 -3.84743102e-02\n",
            "  4.77211550e-03  3.59304510e-02  1.32403886e-02 -2.13542599e-02\n",
            " -3.92179936e-03 -4.70563397e-02  3.53441644e-03  8.56554285e-02\n",
            " -4.75929454e-02 -5.15948199e-02 -1.67313013e-02 -8.69691558e-03\n",
            " -6.94111288e-02 -3.79084631e-05 -2.58450508e-02  7.98432156e-02\n",
            "  1.52362138e-02 -2.55712797e-03  3.76689136e-02 -2.35769227e-02\n",
            "  4.82782051e-02 -1.05142422e-01  1.40893832e-02 -2.24691946e-02\n",
            "  2.28694808e-02 -3.26276459e-02 -1.16899498e-01  2.86654979e-02\n",
            "  3.45434906e-04  3.09233945e-02 -2.25377898e-03  9.53694806e-02\n",
            " -3.82204577e-02 -1.01694018e-02 -2.47867741e-02 -3.58778499e-02\n",
            " -2.75972765e-02  1.00568254e-02 -1.42056182e-01  2.88847219e-02\n",
            " -3.13662589e-02 -7.29207546e-02 -4.08348627e-02  2.05464795e-01\n",
            "  3.96366455e-02  5.52817360e-02  5.05638495e-02 -5.11965416e-02\n",
            "  1.31683424e-02  8.00881907e-03 -4.34509711e-04  5.21956608e-02\n",
            "  1.89864822e-02  2.85810810e-02 -5.28523326e-02 -8.08239076e-03\n",
            " -8.62703752e-03 -4.89501134e-02 -5.52033037e-02 -3.16397665e-04\n",
            "  1.29002288e-01 -2.47845333e-02  1.96873769e-02 -1.52759831e-02\n",
            " -2.61138938e-02  1.62091795e-02  5.08902920e-03 -1.13502247e-02\n",
            " -1.02130197e-01 -6.05005212e-02 -4.68098372e-02 -4.08924840e-33\n",
            " -1.29402019e-02 -5.93999028e-02  5.68358302e-02  4.42596935e-02\n",
            "  1.67620052e-02  5.29366843e-02  4.03798223e-02 -5.51027171e-02\n",
            "  9.59417131e-03 -3.12182121e-02 -8.12139455e-03  4.86012781e-03\n",
            " -3.61402184e-02  7.89580122e-02  6.42039329e-02 -1.65180005e-02\n",
            "  5.35984077e-02  5.84880672e-02 -2.14565117e-02 -3.48468199e-02\n",
            " -5.03309816e-02 -3.78806405e-02  3.19941640e-02  6.10449649e-02\n",
            " -3.32640074e-02 -1.88116394e-02  3.73034010e-04 -1.84503421e-02\n",
            " -4.09012213e-02 -1.14911413e-02  2.44707372e-02  8.34237784e-02\n",
            "  2.49906629e-03  8.09277780e-03  3.65038514e-02  1.15602324e-02\n",
            " -3.05119269e-02 -1.86744537e-02 -2.99855173e-02 -3.84294279e-02\n",
            " -3.05698421e-02  2.42473986e-02 -7.58403614e-02  1.53725157e-02\n",
            " -2.21489416e-03  1.00332208e-03  4.32807319e-02  4.12965119e-02\n",
            " -2.97764242e-02  5.76676652e-02  3.71471606e-02  3.05310683e-03\n",
            "  2.38565616e-02 -2.84868367e-02 -3.83175313e-02 -5.08009270e-02\n",
            "  4.26220261e-02  9.95530374e-03 -3.62583138e-02 -2.91835722e-02\n",
            "  4.57437411e-02  1.37787297e-01 -8.46367236e-03  2.80424487e-02\n",
            " -2.54779421e-02  9.42275766e-03  4.13614884e-03 -2.89254449e-02\n",
            "  8.81157722e-03 -2.15358753e-02  4.44333479e-02 -4.17045727e-02\n",
            "  8.35915655e-02  1.72096062e-02  1.64841171e-02  4.26773913e-02\n",
            " -2.76655518e-02 -1.48798432e-02  4.01365720e-02 -3.10947876e-02\n",
            "  9.53480750e-02 -2.83322781e-02  8.77227411e-02 -5.05807288e-02\n",
            " -3.92715111e-02  5.68964407e-02 -8.73772893e-03 -5.70212603e-02\n",
            "  3.28554288e-02  3.94616909e-02 -8.33975524e-02 -7.49648362e-02\n",
            "  6.29203543e-02 -1.08529599e-02 -1.56646455e-03  3.00255824e-33\n",
            " -3.98583300e-02 -2.21206266e-02  4.39341217e-02  1.07064722e-02\n",
            "  1.93674453e-02 -2.91434210e-02 -1.53652187e-02 -1.25633702e-01\n",
            " -6.41718786e-03 -2.81023514e-03 -3.07835173e-02 -7.30433986e-02\n",
            "  1.14756547e-01 -4.72864695e-03  2.41872184e-02  7.95815364e-02\n",
            "  6.00194857e-02  3.23720388e-02 -4.29123361e-03  4.67560589e-02\n",
            " -4.55566682e-02 -1.76501796e-02 -6.21229447e-02  5.51793054e-02\n",
            " -2.35091839e-02  6.32570609e-02  3.35026570e-02  3.78442593e-02\n",
            " -2.00049412e-02  1.00909416e-02 -1.46968057e-02 -2.61256956e-02\n",
            "  1.21650733e-02 -3.78667228e-02  1.64400879e-02  1.62117213e-01\n",
            " -1.18087893e-02 -9.00578033e-03  4.26814407e-02  5.81880938e-03\n",
            " -5.04290871e-03 -1.68321710e-02  9.38614383e-02  1.67588085e-01\n",
            "  8.30738246e-03 -8.51237308e-03 -2.64110304e-02 -4.52273153e-02\n",
            " -3.08825988e-02  6.13338277e-02 -8.32140818e-02 -6.29006000e-03\n",
            " -2.75612753e-02  6.79955482e-02  4.08384874e-02  5.83025925e-02\n",
            " -1.42011777e-01  3.06584165e-02 -3.41101177e-02 -1.12877831e-01\n",
            " -1.85194779e-02  1.06213437e-02 -3.84150110e-02  8.73773620e-02\n",
            "  3.22289057e-02  5.26221506e-02 -3.06559820e-02 -8.09834301e-02\n",
            " -1.73143763e-02  5.87667525e-02  2.73967627e-02  8.52845684e-02\n",
            "  2.01488081e-02  4.75457311e-03 -8.87099802e-02  6.57350011e-03\n",
            " -7.11209103e-02  4.02990580e-02 -3.40328924e-02  6.76417723e-04\n",
            "  5.70782740e-03 -5.08691184e-02 -6.90661147e-02  3.35180052e-02\n",
            " -3.38987224e-02 -9.94492173e-02  7.04995990e-02  1.91738345e-02\n",
            " -3.98948453e-02 -4.22833301e-02  1.01989962e-03  7.75988027e-02\n",
            " -1.89054944e-02  2.80181784e-02  4.08031121e-02 -1.13361098e-08\n",
            "  4.43254896e-02 -6.11978583e-02 -9.04650241e-02  1.06994892e-02\n",
            "  6.17540218e-02 -2.41269358e-02 -3.03669870e-02 -3.54954861e-02\n",
            "  4.24247682e-02  3.38702686e-02 -4.82231155e-02  8.18262100e-02\n",
            "  4.69875000e-02  2.35524904e-02 -4.81081894e-03 -3.95317748e-03\n",
            "  2.72769015e-02 -6.52630702e-02  2.36459654e-02  8.78034830e-02\n",
            " -2.89821299e-03 -4.83062491e-03 -6.41031517e-03  1.20106069e-02\n",
            " -4.65846108e-03 -2.54760776e-02  4.07904349e-02  8.06343406e-02\n",
            "  7.39319324e-02  4.28057685e-02  2.17353664e-02 -3.40661928e-02\n",
            " -5.48620857e-02 -3.74728553e-02 -2.41043651e-03 -5.19345030e-02\n",
            " -2.59677544e-02 -4.69869673e-02  4.14009877e-02 -4.41033058e-02\n",
            " -1.96241550e-02  3.64377769e-03 -2.04256959e-02 -3.44890207e-02\n",
            " -6.28785938e-02 -1.38180144e-02 -8.50541443e-02 -4.57920991e-02\n",
            " -9.28543955e-02  5.19761723e-03 -2.16424204e-02  4.01506014e-02\n",
            "  4.40203771e-02  3.65745686e-02  1.04530893e-01  3.81166674e-02\n",
            "  3.46878767e-02  1.37622327e-01 -1.74716543e-02  7.74102435e-02\n",
            "  3.54539901e-02  2.89898012e-02  5.62974028e-02 -3.18796560e-02]\n",
            "Cosine similarity: 0.23459944128990173\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # klein & schnell; gute Qualität\n",
        "\n",
        "def embed(texts):\n",
        "    # texts: str or list[str]\n",
        "    return model.encode(texts, convert_to_numpy=True, normalize_embeddings=False)\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    # numerisch stabil: L2-normalisieren dann dot\n",
        "    a = a / np.linalg.norm(a)\n",
        "    b = b / np.linalg.norm(b)\n",
        "    return float(np.dot(a, b))\n",
        "\n",
        "# Beispiel\n",
        "t1 = \"Das ist ein Beispieltext.\"\n",
        "t2 = \"Das ist ein Beispieltext.\"\n",
        "t2 = \"Döner\"\n",
        "t1 = \"Pizza\"\n",
        "v1, v2 = embed([t1, t2])\n",
        "\n",
        "\n",
        "print(v1)\n",
        "print(\"Cosine similarity:\", cosine_sim(v1, v2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "c:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\brand\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:  Brandon Hank: \"Im März 2025 habe ich mein Masterstudium in Artificial Intelligence & Data Science an der Heinrich-Heine-Universität Düsseldorf erfolgreich abgeschlossen\" \"Ich bewerbe mich als AI-Engineer bei Thalia, weil mich die Möglichkeit begeistert\"\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# using pipeline API for summarization task\n",
        "summarization = pipeline(\"summarization\")\n",
        "\n",
        "\n",
        "original_text = \"\"\"\n",
        "Im März 2025 habe ich mein Masterstudium in Artificial Intelligence & Data Science an der Heinrich-Heine-Universität Düsseldorf erfolgreich abgeschlossen. Dabei konnte ich fundierte Kenntnisse in Machine Learning, Datenverarbeitung und Datenvisualisierung erwerben, die ich nun gezielt in der Praxis einsetzen möchte. \n",
        "Praxisbezogene Erfahrungen sammelte ich am Forschungszentrum Jülich sowie beim Deutschen Zentrum für Luft- und Raumfahrt (DLR) in Sankt Augustin. Im Rahmen meiner Masterarbeit entwickelte und validierte ich ML-basierte Graphmodelle zur Analyse hydraulischer Systeme. Diese Arbeit verband die Verarbeitung komplexer technischer Daten mit der Entwicklung praxistauglicher Algorithmen. \n",
        "Ich bewerbe mich als AI-Engineer bei Thalia, weil mich die Möglichkeit begeistert, mit Generative AI echte Innovationen im Buchhandel mitzugestalten. Mit meinem Background in Machine Learning und Erfahrung mit Python, ML-Frameworks und Datenanalyse kann ich helfen, KI-Modelle zu entwickeln und produktiv einzusetzen. Ich arbeite strukturiert und verantwortungsbewusst und liebe es, technische Konzepte praktisch umzusetzen. Ich freue mich darauf, mit meiner Expertise zum digitalen Wandel bei Thalia beizutragen. \n",
        "Ich gelte als engagiert, lernbereit und teamorientiert. In bisherigen Stationen wurde meine Fähigkeit geschätzt, mich schnell in neue Themen einzuarbeiten, Ideen proaktiv einzubringen und konstruktiv mit Fach- und Führungskräften zusammenzuarbeiten. Auch wäre Ich bereit, bei einer erfolgreichen Bewerbungsprozess meinen Wohnort zu wechseln.  \n",
        "Ich stehe Ihnen kurzfristig zur Verfügung und freue mich, Sie in einem persönlichen Gespräch von meiner Motivation und meinen Fähigkeiten zu überzeugen. \n",
        "Mit freundlichen Grüßen,  \n",
        "Brandon (Roby) Hank \n",
        "\"\"\"\n",
        "\n",
        "summary_text = summarization(original_text)[0]['summary_text']\n",
        "print(\"Summary:\", summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:  Dieses Gesetz ist einfach nur Unfug. Es schadet den kleinen und mittleren Unternehmen in unserem Land. Wir haben es beim Verbrenner-Aus gesehen; wir sehen es immer noch. Heute bekommen es quasi vor den Latz geknallt. Es bewirkt genau das Gegenteil von dem, was Sie gestern eigentlich bewirken wollten. Es ist der nächste Klotz am Bein unserer ohnehin gebeutelten\n"
          ]
        }
      ],
      "source": [
        "\n",
        "summary_text = summarization(reden[\"Leif-Erik Holm\"][:1000])[0]['summary_text']\n",
        "print(\"Summary:\", summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redner: Bärbel Bas\n",
            "Zusammenfassung:  500 Milliarden Euro – 500 million Euro – ise viel Geld in die Hand genommen, um unser Land voranzubringen . Wir investieren in Kitas, in Schulen, in Krankenhäuser, in Klimaschutz. Wir stärken die kritische Infrastruktur, auch in Zeiten neuartiger Bedrohungen .\n",
            "\n",
            "Redner: Hans-Jürgen Goßner\n",
            "Zusammenfassung:  Tariftreuegesetz ist wieder einmal ein Paradebeispiel deutscher Bürokratiepolitik . Wer solche Widersprüche produziert, gehört nicht in die Regierung, sondern auf die Comedybühne .\n",
            "\n",
            "Redner: Wilfried Oellers\n",
            "Zusammenfassung:  Der Gesetzentwurf tangiert Artikel 9 Absatz 3 GG insoweit, als dass negative Koalitionsfreiheit davon betroffen ist . Es sollen gerade nicht durch niedrigere Lohnzahlungen günstigere Angebote auf dem Rücken der Beschäftigten abgegeben werden .\n",
            "\n",
            "Redner: Ricarda Lang\n",
            "Zusammenfassung:  Die AfD hetzt gegegen die Rechte von Arbeitnehmern, nur um sich dann im eigenen Wahlkreis wieder als die Partei des kleinen Mannes aufzuspielen . Sie beweisen hier aber jede einzelne Woche: Sie sind the unsozialste Partei in diesem Deutschland .\n",
            "\n",
            "Redner: Pascal Meiser\n",
            "Zusammenfassung:  Meine Damen und Herren: Wir alle wissen: Tarifflucht schmutzige Wettbewerbsvorteile . Doch immer mehr mehr Unternehmen entziehen sich ihrer sozialen Verantwortung .\n",
            "\n",
            "Redner: Dagmar Schmidt\n",
            "Zusammenfassung:  500 Milliarden Euro Sondervermögen ist ein riesengroßer Modernisierungspakt für unser Land . Wir investieren unter anderem in klimafreundliche Energie, in den Ausbau der Bahn, in die Sanierung von Brücken and Straßen, in eine digitale Verwaltung .\n",
            "\n",
            "Redner: Peter Bohnhof\n",
            "Zusammenfassung:  Für diese Regierung gilt nämlich in der ganzen Legislatur der Grundsatz: Erst versprochen, dann gebrochen . Die Wahrheit ist ein massiver Eingriff in unsere Wirtschaftsfreihe, der auf faire Chancen hofft .\n",
            "\n",
            "Redner: Sandra Carstensen\n",
            "Zusammenfassung:  Uns von CDU/CSU, SPD, Grünen and Linke eint der Wunsch, mit diesem Tariftreuegesetz etwas Gutes zu bewirken . Weil die Zahl der Verträge mit Tarifbindung ist stark rückläufig ist, haben wir, die SPD, gemeinsam vereinbart und uns vorgenommen .\n",
            "\n",
            "Redner: Armin Grau\n",
            "Zusammenfassung:  Weniger als die Hälfte der Beschäftigten profitieren heute noch von einem Tarifvertrag . Der Staat darf mit öffentlichem Geld kein Lohn- und Sozialdumping unterstützen .\n",
            "\n",
            "Redner: Nora Seitz\n",
            "Zusammenfassung:  Bundestariftreuegesetz verfolgt richtige und notwendige Ziele: Bei der Vergabe öffentlicher Aufträge sollen faire und für all Arbeitnehmer geltende Wettbewerbsbedingungen geschaffen werden .\n",
            "\n",
            "Redner: Leif-Erik Holm\n",
            "Zusammenfassung:  Dieses Gesetz ist einfach nur Unfug. Es schadet den kleinen und mittleren Unternehmen in unserem Land. Wir haben es beim Verbrenner-Aus gesehen; wir sehen es immer noch. Heute bekommen es quasi vor den Latz geknallt. Es bewirkt genau das Gegenteil von dem, was Sie gestern eigentlich bewirken wollten. Es ist der nächste Klotz am Bein unserer ohnehin gebeutelten\n",
            "\n",
            "Redner: Peter Aumer\n",
            "Zusammenfassung:  Faire Löhne sichern, Tarifbindung stärken und gute Arbeit fördern: Das ist das Ziel des Tariftreuegesetzes . Unsere soziale Marktwirtschaft lebt vom Gleichgewicht zwischen Freiheit und Verantwortung .\n",
            "\n",
            "Redner: Jan Dieren\n",
            "Zusammenfassung:  In den kommenden Jahren werden wir sehr, sehr viel Geld in die Modernisierung unserer Infrastruktur stecken . Aber Geld baut keine Straßen, Brücken oder Bahngleise; das tun Menschen.\n",
            "\n",
            "Redner: Elisabeth Winkelmeier-Becker\n",
            "Zusammenfassung:  Wirtschaftsministerium and Arbeitsministerial legen diesen Gesetzentwurf vor . Ziel ist es, den fairen Wettbewerb und die Tarifbindung zu stärken, denn das Ziel ‘Wohlstand für all“ braucht gute und faire Bezahlung für die Beschäftigten .\n",
            "\n",
            "Redner: Tobias Matthias Peterka\n",
            "Zusammenfassung:  Dutzend Polizisten und ein grinsender Staatsanwalt, oft sehr motiviert und voller Vorfreude auf Machtrausch des Technokraten, der ihn seinerseits an diesem Tag so früh aus dem Bett getrieben . Neutrale Ermittlungen aufgrund von Anzeigen ohne vorherigen Gesinnungsabgleich sind eine Sache; das gehört natürlich zu einem Rechtsstaat .\n",
            "\n",
            "Redner: Axel Müller\n",
            "Zusammenfassung:  Am 12. September dieses Jahres brachte die AfD einen Gesetzentwurf zur Abschaffung des §188 StGB . The wahre Grund für §188 ist jedoch ein anderer. 2019 wurde der Kasseler Regierungspräsident Walter Lübcke ermordet .\n",
            "\n",
            "Redner: Lena Gumnior\n",
            "Zusammenfassung:  Durchsuchung wurde die Bundesgeschäftsstelle der AfD, und es gab bei Bernd Höcke, Petr Bystron und Maximilian Krah . Alice Weidel liebt es, Menschen anzuzeigen oder von ihren Leuten anzeigen zu lassen. Und die kennt sich mit Strafanzeigen nach §188 StGB bestens aus: Hunderte Anzeigen regnete es klammheimlich.\n",
            "\n",
            "Redner: Mahmut Özdemir\n",
            "Zusammenfassung:  Ehrabschneidungen, Verschmähungen, unwahre Tatsachen areeine Strafverfolgung zuwider ist ausgerechnet für Delikte in Ihrer Paradedisziplin . Ihnen wollen die Meinungsfreiheit stärken mit Ihrem Gesetz .\n",
            "\n",
            "Redner: Luke Hoß\n",
            "Zusammenfassung:  Vor ein paar Wochen lag uns ein ähnlicher Antrag der AfD vor vor. Vermeintlich wollte die AfD gegen die Sonderbehandlung von Politikerinnen and Politikern im Strafrecht vorgehen. Anzeigen frühmorgens bewaffnete Polizisten  stehen .\n",
            "\n",
            "Redner: Christian Moser\n",
            "Zusammenfassung:  Anordnungen von Hausdurchsuchungen wegen Beleidigungsdelikten statt. The Präsidentin: Die Verhältnismäßigkeitsprüfung funktioniert nicht. Thee finde ich gar nicht so üppig.\n",
            "\n",
            "Redner: Rainer Galla\n",
            "Zusammenfassung:  In jüngster Zeit erleben wir einen gefährlichen Trend: Die Verfolgung von Tatbeständen in der Politikerbeleidigung führt immer öfter zu Durchsuchungen von Räumlichkeiten .\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, text \u001b[38;5;129;01min\u001b[39;00m reden.items():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRedner: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mZusammenfassung: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msummarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msummary_text\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:303\u001b[39m, in \u001b[36mSummarizationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    280\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    282\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    301\u001b[39m \u001b[33;03m          ids of the summary.\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    193\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    194\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    195\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    196\u001b[39m     ):\n\u001b[32m    197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:220\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    218\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\generation\\utils.py:3265\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3262\u001b[39m flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3263\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3265\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3267\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3268\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3269\u001b[39m     model_outputs,\n\u001b[32m   3270\u001b[39m     model_kwargs,\n\u001b[32m   3271\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3272\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1472\u001b[39m, in \u001b[36mBartForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1468\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1469\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1470\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1482\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1491\u001b[39m lm_logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m])\n\u001b[32m   1492\u001b[39m lm_logits = lm_logits + \u001b[38;5;28mself\u001b[39m.final_logits_bias.to(lm_logits.device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1289\u001b[39m, in \u001b[36mBartModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1282\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1283\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1284\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1285\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1286\u001b[39m     )\n\u001b[32m   1288\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1122\u001b[39m, in \u001b[36mBartDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dropout_probability < \u001b[38;5;28mself\u001b[39m.layerdrop:\n\u001b[32m   1120\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:452\u001b[39m, in \u001b[36mBartDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_values, output_attentions, use_cache, cache_position)\u001b[39m\n\u001b[32m    450\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.activation_fn(\u001b[38;5;28mself\u001b[39m.fc1(hidden_states))\n\u001b[32m    451\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.activation_dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    454\u001b[39m hidden_states = residual + hidden_states\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brand\\anaconda3\\envs\\job\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "for name, text in reden.items():\n",
        "    print(f\"Redner: {name}\\nZusammenfassung: {summarization(text[:1000])[0]['summary_text']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765), 'rougeL': Score(precision=0.625, recall=0.5555555555555556, fmeasure=0.5882352941176471)}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "# Initialisierung des Scorers\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "# Vergleich von zwei Texten\n",
        "scores = scorer.score(\n",
        "   'Der schnelle braune Fuchs springt über den faulen Hund.',\n",
        "   'Der schnelle braune Hund springt auf den Baum.'\n",
        ")\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP50MDuGDSS8xYQVPOiGNTy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "job",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
